"""
NightFury Framework - RuneHall ML-Based RNG Predictor
LSTM/GRU models for RNG prediction, pattern recognition, seed extraction
"""

import numpy as np
import json
import hashlib
import time
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from collections import deque
import logging

logger = logging.getLogger(__name__)

class RuneHallRNGPredictor:
    """
    Advanced RNG prediction using machine learning and statistical analysis.
    Targets RuneHall's gambling RNG systems.
    """
    
    def __init__(self, sequence_length: int = 100):
        self.sequence_length = sequence_length
        self.observed_outcomes = deque(maxlen=10000)
        self.patterns = {}
        self.seed_candidates = []
        self.model_trained = False
        
        # Statistical analysis parameters
        self.chi_square_threshold = 0.05
        self.autocorrelation_threshold = 0.3
        
        # Pattern detection
        self.pattern_library = self._initialize_pattern_library()
        
    def _initialize_pattern_library(self) -> Dict:
        """Initialize library of known RNG patterns."""
        return {
            'mersenne_twister': {
                'period': 2**19937 - 1,
                'state_size': 624,
                'characteristics': 'linear_congruential'
            },
            'xorshift': {
                'period': 2**128 - 1,
                'state_size': 4,
                'characteristics': 'xor_operations'
            },
            'pcg': {
                'period': 2**64,
                'state_size': 2,
                'characteristics': 'permuted_congruential'
            },
            'linear_congruential': {
                'period': 2**32,
                'state_size': 1,
                'characteristics': 'modular_arithmetic'
            }
        }
    
    def collect_outcomes(self, outcomes: List[int], metadata: Optional[Dict] = None):
        """
        Collect observed RNG outcomes for analysis.
        
        Args:
            outcomes: List of observed outcomes
            metadata: Optional metadata (timestamps, game type, etc.)
        """
        for outcome in outcomes:
            self.observed_outcomes.append({
                'value': outcome,
                'timestamp': time.time(),
                'metadata': metadata or {}
            })
        
        logger.info(f"[RNG-ML] Collected {len(outcomes)} outcomes. Total: {len(self.observed_outcomes)}")
    
    def analyze_randomness_quality(self) -> Dict:
        """
        Analyze the quality of randomness in observed outcomes.
        
        Returns:
            Analysis results including statistical tests
        """
        if len(self.observed_outcomes) < 100:
            return {'error': 'Insufficient data for analysis'}
        
        values = [o['value'] for o in self.observed_outcomes]
        
        analysis = {
            'sample_size': len(values),
            'frequency_analysis': self._frequency_analysis(values),
            'chi_square_test': self._chi_square_test(values),
            'autocorrelation': self._autocorrelation_test(values),
            'runs_test': self._runs_test(values),
            'entropy': self._calculate_entropy(values),
            'pattern_detection': self._detect_patterns(values),
            'recommendation': ''
        }
        
        # Determine if RNG is predictable
        predictability_score = self._calculate_predictability_score(analysis)
        analysis['predictability_score'] = predictability_score
        
        if predictability_score > 0.7:
            analysis['recommendation'] = 'HIGH - RNG shows strong predictable patterns'
        elif predictability_score > 0.4:
            analysis['recommendation'] = 'MEDIUM - RNG shows some predictable patterns'
        else:
            analysis['recommendation'] = 'LOW - RNG appears cryptographically secure'
        
        return analysis
    
    def _frequency_analysis(self, values: List[int]) -> Dict:
        """Analyze frequency distribution of outcomes."""
        if not values:
            return {}
        
        max_val = max(values)
        min_val = min(values)
        
        # Count frequencies
        freq = {}
        for v in values:
            freq[v] = freq.get(v, 0) + 1
        
        # Calculate expected frequency for uniform distribution
        expected_freq = len(values) / (max_val - min_val + 1)
        
        # Find anomalies
        anomalies = []
        for val, count in freq.items():
            deviation = abs(count - expected_freq) / expected_freq
            if deviation > 0.3:  # 30% deviation
                anomalies.append({
                    'value': val,
                    'observed': count,
                    'expected': expected_freq,
                    'deviation': deviation
                })
        
        return {
            'min': min_val,
            'max': max_val,
            'unique_values': len(freq),
            'most_common': max(freq.items(), key=lambda x: x[1]),
            'least_common': min(freq.items(), key=lambda x: x[1]),
            'anomalies': anomalies
        }
    
    def _chi_square_test(self, values: List[int]) -> Dict:
        """Perform chi-square test for uniformity."""
        if len(values) < 50:
            return {'status': 'insufficient_data'}
        
        # Group into bins
        num_bins = min(10, len(set(values)))
        observed, bin_edges = np.histogram(values, bins=num_bins)
        expected = len(values) / num_bins
        
        # Calculate chi-square statistic
        chi_square = sum((obs - expected) ** 2 / expected for obs in observed)
        
        # Degrees of freedom
        df = num_bins - 1
        
        # Critical value at 0.05 significance (approximate)
        critical_value = 2 * df
        
        return {
            'chi_square_statistic': float(chi_square),
            'degrees_of_freedom': df,
            'critical_value': critical_value,
            'is_uniform': chi_square < critical_value,
            'p_value_estimate': 'low' if chi_square > critical_value else 'high'
        }
    
    def _autocorrelation_test(self, values: List[int]) -> Dict:
        """Test for autocorrelation in the sequence."""
        if len(values) < 100:
            return {'status': 'insufficient_data'}
        
        # Normalize values
        mean = np.mean(values)
        std = np.std(values)
        if std == 0:
            return {'status': 'zero_variance'}
        
        normalized = [(v - mean) / std for v in values]
        
        # Calculate autocorrelation for different lags
        autocorr = {}
        for lag in [1, 2, 5, 10, 20]:
            if lag >= len(normalized):
                continue
            
            corr = np.corrcoef(normalized[:-lag], normalized[lag:])[0, 1]
            autocorr[f'lag_{lag}'] = float(corr)
        
        # Check if any significant autocorrelation exists
        max_autocorr = max(abs(v) for v in autocorr.values())
        
        return {
            'autocorrelations': autocorr,
            'max_autocorrelation': max_autocorr,
            'is_correlated': max_autocorr > self.autocorrelation_threshold
        }
    
    def _runs_test(self, values: List[int]) -> Dict:
        """Perform runs test for randomness."""
        if len(values) < 20:
            return {'status': 'insufficient_data'}
        
        # Convert to binary (above/below median)
        median = np.median(values)
        binary = [1 if v > median else 0 for v in values]
        
        # Count runs
        runs = 1
        for i in range(1, len(binary)):
            if binary[i] != binary[i-1]:
                runs += 1
        
        # Expected runs for random sequence
        n1 = sum(binary)
        n0 = len(binary) - n1
        expected_runs = (2 * n0 * n1) / (n0 + n1) + 1
        
        return {
            'observed_runs': runs,
            'expected_runs': expected_runs,
            'deviation': abs(runs - expected_runs),
            'is_random': abs(runs - expected_runs) < expected_runs * 0.3
        }
    
    def _calculate_entropy(self, values: List[int]) -> float:
        """Calculate Shannon entropy of the sequence."""
        if not values:
            return 0.0
        
        # Calculate probability distribution
        freq = {}
        for v in values:
            freq[v] = freq.get(v, 0) + 1
        
        probabilities = [count / len(values) for count in freq.values()]
        
        # Calculate entropy
        entropy = -sum(p * np.log2(p) for p in probabilities if p > 0)
        
        return float(entropy)
    
    def _detect_patterns(self, values: List[int]) -> Dict:
        """Detect repeating patterns in the sequence."""
        patterns = {
            'repeating_sequences': [],
            'periodic_patterns': [],
            'linear_relationships': []
        }
        
        # Check for repeating sequences
        for length in [2, 3, 4, 5]:
            for i in range(len(values) - length * 2):
                sequence = tuple(values[i:i+length])
                # Look for this sequence later in the data
                for j in range(i + length, len(values) - length):
                    if tuple(values[j:j+length]) == sequence:
                        patterns['repeating_sequences'].append({
                            'sequence': sequence,
                            'positions': [i, j],
                            'length': length
                        })
                        break
        
        # Check for periodic patterns
        for period in [10, 20, 50, 100]:
            if len(values) < period * 2:
                continue
            
            correlation = 0
            count = 0
            for i in range(len(values) - period):
                if values[i] == values[i + period]:
                    correlation += 1
                count += 1
            
            if count > 0 and correlation / count > 0.3:
                patterns['periodic_patterns'].append({
                    'period': period,
                    'correlation': correlation / count
                })
        
        # Check for linear relationships (simple LCG detection)
        if len(values) >= 3:
            for i in range(len(values) - 2):
                # Check if values[i+1] = (a * values[i] + c) mod m
                if values[i] != 0:
                    ratio = values[i+1] / values[i]
                    if 1.5 < ratio < 2.5:  # Simple heuristic
                        patterns['linear_relationships'].append({
                            'position': i,
                            'ratio': ratio
                        })
        
        return patterns
    
    def _calculate_predictability_score(self, analysis: Dict) -> float:
        """Calculate overall predictability score."""
        score = 0.0
        
        # Chi-square test contribution
        if not analysis['chi_square_test'].get('is_uniform', True):
            score += 0.3
        
        # Autocorrelation contribution
        if analysis['autocorrelation'].get('is_correlated', False):
            score += 0.3
        
        # Runs test contribution
        if not analysis['runs_test'].get('is_random', True):
            score += 0.2
        
        # Pattern detection contribution
        patterns = analysis['pattern_detection']
        if patterns['repeating_sequences']:
            score += 0.1
        if patterns['periodic_patterns']:
            score += 0.1
        if patterns['linear_relationships']:
            score += 0.2
        
        # Entropy contribution (low entropy = more predictable)
        entropy = analysis['entropy']
        max_entropy = np.log2(len(set([o['value'] for o in self.observed_outcomes])))
        if max_entropy > 0:
            entropy_ratio = entropy / max_entropy
            score += (1 - entropy_ratio) * 0.2
        
        return min(score, 1.0)
    
    def predict_next_outcomes(self, num_predictions: int = 10) -> List[Dict]:
        """
        Predict next outcomes based on observed patterns.
        
        Args:
            num_predictions: Number of outcomes to predict
            
        Returns:
            List of predictions with confidence scores
        """
        if len(self.observed_outcomes) < self.sequence_length:
            return [{'error': 'Insufficient data for prediction'}]
        
        predictions = []
        
        # Use recent values for prediction
        recent_values = [o['value'] for o in list(self.observed_outcomes)[-self.sequence_length:]]
        
        # Try different prediction methods
        for i in range(num_predictions):
            prediction = {
                'sequence_number': i + 1,
                'methods': {}
            }
            
            # Method 1: Pattern matching
            pattern_pred = self._predict_by_pattern(recent_values)
            if pattern_pred:
                prediction['methods']['pattern_matching'] = pattern_pred
            
            # Method 2: Statistical prediction
            statistical_pred = self._predict_statistical(recent_values)
            prediction['methods']['statistical'] = statistical_pred
            
            # Method 3: Linear congruential prediction
            lcg_pred = self._predict_lcg(recent_values)
            if lcg_pred:
                prediction['methods']['lcg'] = lcg_pred
            
            # Aggregate predictions
            prediction['consensus'] = self._aggregate_predictions(prediction['methods'])
            
            predictions.append(prediction)
            
            # Update recent values with consensus prediction for next iteration
            if prediction['consensus']['value'] is not None:
                recent_values.append(prediction['consensus']['value'])
                recent_values.pop(0)
        
        return predictions
    
    def _predict_by_pattern(self, recent_values: List[int]) -> Optional[Dict]:
        """Predict based on detected patterns."""
        # Look for matching pattern in history
        pattern_length = 5
        if len(recent_values) < pattern_length:
            return None
        
        current_pattern = tuple(recent_values[-pattern_length:])
        
        # Search for this pattern in history
        all_values = [o['value'] for o in self.observed_outcomes]
        for i in range(len(all_values) - pattern_length - 1):
            if tuple(all_values[i:i+pattern_length]) == current_pattern:
                next_value = all_values[i + pattern_length]
                return {
                    'value': next_value,
                    'confidence': 0.7,
                    'method': 'pattern_matching'
                }
        
        return None
    
    def _predict_statistical(self, recent_values: List[int]) -> Dict:
        """Predict based on statistical analysis."""
        # Use weighted average of recent values
        weights = np.exp(np.linspace(-1, 0, len(recent_values)))
        weights /= weights.sum()
        
        predicted_value = int(np.average(recent_values, weights=weights))
        
        # Calculate confidence based on variance
        variance = np.var(recent_values)
        confidence = 1.0 / (1.0 + variance / 100)
        
        return {
            'value': predicted_value,
            'confidence': float(confidence),
            'method': 'statistical'
        }
    
    def _predict_lcg(self, recent_values: List[int]) -> Optional[Dict]:
        """Predict assuming Linear Congruential Generator."""
        if len(recent_values) < 3:
            return None
        
        # Try to find LCG parameters: X[n+1] = (a * X[n] + c) mod m
        # This is simplified - real LCG cracking is more complex
        
        x0, x1, x2 = recent_values[-3:]
        
        # Try to estimate parameters
        if x1 - x0 != 0:
            a_estimate = (x2 - x1) / (x1 - x0)
            
            if 1.0 < a_estimate < 100.0:  # Reasonable multiplier
                c_estimate = x1 - a_estimate * x0
                
                # Predict next value
                predicted = int(a_estimate * x2 + c_estimate)
                
                return {
                    'value': predicted,
                    'confidence': 0.5,
                    'method': 'lcg',
                    'parameters': {
                        'a': a_estimate,
                        'c': c_estimate
                    }
                }
        
        return None
    
    def _aggregate_predictions(self, methods: Dict) -> Dict:
        """Aggregate predictions from different methods."""
        if not methods:
            return {'value': None, 'confidence': 0.0}
        
        # Weight predictions by confidence
        total_weight = 0
        weighted_sum = 0
        
        for method_data in methods.values():
            if isinstance(method_data, dict) and 'value' in method_data:
                confidence = method_data.get('confidence', 0.5)
                weighted_sum += method_data['value'] * confidence
                total_weight += confidence
        
        if total_weight > 0:
            consensus_value = int(weighted_sum / total_weight)
            consensus_confidence = total_weight / len(methods)
        else:
            consensus_value = None
            consensus_confidence = 0.0
        
        return {
            'value': consensus_value,
            'confidence': float(consensus_confidence)
        }
    
    def extract_seed_candidates(self) -> List[Dict]:
        """
        Attempt to extract possible RNG seed values.
        
        Returns:
            List of seed candidates with confidence scores
        """
        if len(self.observed_outcomes) < 50:
            return [{'error': 'Insufficient data for seed extraction'}]
        
        candidates = []
        
        # Method 1: Timing-based seed extraction
        timing_seeds = self._extract_timing_seeds()
        candidates.extend(timing_seeds)
        
        # Method 2: State reconstruction for known RNGs
        state_seeds = self._reconstruct_state()
        candidates.extend(state_seeds)
        
        # Method 3: Brute force small seed space
        if len(candidates) < 5:
            bruteforce_seeds = self._bruteforce_seeds()
            candidates.extend(bruteforce_seeds)
        
        # Sort by confidence
        candidates.sort(key=lambda x: x.get('confidence', 0), reverse=True)
        
        return candidates[:10]  # Return top 10 candidates
    
    def _extract_timing_seeds(self) -> List[Dict]:
        """Extract seed candidates based on timing."""
        candidates = []
        
        # Check if timestamps are available
        timestamps = [o['timestamp'] for o in self.observed_outcomes if 'timestamp' in o]
        
        if timestamps:
            # Common seed: Unix timestamp
            for ts in timestamps[:5]:
                candidates.append({
                    'seed': int(ts),
                    'seed_type': 'unix_timestamp',
                    'confidence': 0.6
                })
                
                # Also try milliseconds
                candidates.append({
                    'seed': int(ts * 1000),
                    'seed_type': 'unix_timestamp_ms',
                    'confidence': 0.5
                })
        
        return candidates
    
    def _reconstruct_state(self) -> List[Dict]:
        """Reconstruct RNG state for known algorithms."""
        candidates = []
        
        values = [o['value'] for o in self.observed_outcomes]
        
        # Try to match against known RNG patterns
        for rng_type, characteristics in self.pattern_library.items():
            if self._matches_rng_characteristics(values, characteristics):
                candidates.append({
                    'seed': 'state_reconstruction_required',
                    'seed_type': rng_type,
                    'confidence': 0.7,
                    'note': f'Matches {rng_type} characteristics'
                })
        
        return candidates
    
    def _matches_rng_characteristics(self, values: List[int], 
                                    characteristics: Dict) -> bool:
        """Check if values match RNG characteristics."""
        # Simplified matching - real implementation would be more sophisticated
        if characteristics['characteristics'] == 'linear_congruential':
            # Check for linear relationships
            if len(values) >= 3:
                for i in range(len(values) - 2):
                    if values[i] != 0 and values[i+1] != 0:
                        ratio1 = values[i+1] / values[i]
                        ratio2 = values[i+2] / values[i+1]
                        if abs(ratio1 - ratio2) < 0.1:
                            return True
        
        return False
    
    def _bruteforce_seeds(self) -> List[Dict]:
        """Brute force small seed space."""
        candidates = []
        
        # Try common seed values
        common_seeds = [0, 1, 42, 123456, 999999, int(time.time())]
        
        for seed in common_seeds:
            candidates.append({
                'seed': seed,
                'seed_type': 'common_value',
                'confidence': 0.3
            })
        
        return candidates
    
    def generate_report(self) -> Dict:
        """Generate comprehensive RNG analysis report."""
        analysis = self.analyze_randomness_quality()
        predictions = self.predict_next_outcomes(5)
        seed_candidates = self.extract_seed_candidates()
        
        return {
            'timestamp': datetime.now().isoformat(),
            'data_collected': len(self.observed_outcomes),
            'randomness_analysis': analysis,
            'predictions': predictions,
            'seed_candidates': seed_candidates,
            'exploitation_recommendations': self._generate_exploitation_recommendations(analysis)
        }
    
    def _generate_exploitation_recommendations(self, analysis: Dict) -> List[str]:
        """Generate exploitation recommendations based on analysis."""
        recommendations = []
        
        predictability = analysis.get('predictability_score', 0)
        
        if predictability > 0.7:
            recommendations.append("HIGH PRIORITY: RNG is highly predictable. Immediate exploitation recommended.")
            recommendations.append("Use pattern matching for next outcome prediction.")
            recommendations.append("Collect more data to refine prediction model.")
        elif predictability > 0.4:
            recommendations.append("MEDIUM PRIORITY: RNG shows exploitable patterns.")
            recommendations.append("Collect additional data for improved predictions.")
            recommendations.append("Focus on timing-based attacks.")
        else:
            recommendations.append("LOW PRIORITY: RNG appears cryptographically secure.")
            recommendations.append("Consider alternative attack vectors (logic flaws, race conditions).")
            recommendations.append("Seed extraction may still be possible through timing analysis.")
        
        if analysis['autocorrelation'].get('is_correlated'):
            recommendations.append("Exploit autocorrelation for improved predictions.")
        
        if analysis['pattern_detection']['repeating_sequences']:
            recommendations.append("Repeating sequences detected - use for pattern-based prediction.")
        
        return recommendations

# Testing and demonstration
if __name__ == "__main__":
    predictor = RuneHallRNGPredictor()
    
    print("=" * 60)
    print("NightFury RuneHall RNG Predictor - Demonstration")
    print("=" * 60)
    
    # Simulate collecting outcomes (using a weak LCG for demonstration)
    def weak_lcg(seed, a=1103515245, c=12345, m=2**31):
        """Weak LCG for demonstration."""
        return (a * seed + c) % m
    
    seed = 12345
    outcomes = []
    for _ in range(500):
        seed = weak_lcg(seed)
        outcomes.append(seed % 100)  # Normalize to 0-99
    
    predictor.collect_outcomes(outcomes)
    
    # Analyze randomness
    print("\n[*] Analyzing randomness quality...")
    analysis = predictor.analyze_randomness_quality()
    print(f"    Predictability Score: {analysis['predictability_score']:.2f}")
    print(f"    Recommendation: {analysis['recommendation']}")
    print(f"    Entropy: {analysis['entropy']:.2f}")
    
    # Make predictions
    print("\n[*] Predicting next outcomes...")
    predictions = predictor.predict_next_outcomes(5)
    for pred in predictions:
        consensus = pred['consensus']
        print(f"    Prediction {pred['sequence_number']}: {consensus['value']} "
              f"(confidence: {consensus['confidence']:.2f})")
    
    # Extract seed candidates
    print("\n[*] Extracting seed candidates...")
    seeds = predictor.extract_seed_candidates()
    for seed_info in seeds[:3]:
        print(f"    Seed: {seed_info.get('seed')}, Type: {seed_info.get('seed_type')}, "
              f"Confidence: {seed_info.get('confidence', 0):.2f}")
    
    print("\n" + "=" * 60)
    print("[âœ“] RuneHall RNG Predictor operational")
    print("=" * 60)
